{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TOPF import *\n",
    "from TOPFbasics import *\n",
    "from Sampling import *\n",
    "import Bio.PDB.PDBList\n",
    "from Bio.PDB.MMCIFParser import MMCIFParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreate the point cloud from Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1 = thick_sphere(dens, 0.6, 1)\n",
    "ts2 = thick_sphere(dens, 0.6, 1)+[4, 0]\n",
    "tr = filled_rectangle(dens, 3, 0.5)+[0, -0.25]\n",
    "tr4 = filled_rectangle(dens, 2, 0.5)+[1, -0.25]\n",
    "ttotal = np.concatenate((ts2, tr), axis=0)\n",
    "ttotal2 = np.concatenate((ts1, ts2, tr4), axis=0)+[0, 4]\n",
    "tr2 = filled_rectangle(dens, 0.5, 3)+[-0.25, 0]\n",
    "tr3 = filled_rectangle(dens, 0.5, 2)+[3.75, 1]\n",
    "three_circles = np.concatenate((ttotal, ttotal2, tr2, tr3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, sigantures = topf_run(three_circles, draw_final_clustering=True, draw_scaled_vecs=True, simplex_chances=[1,1], draw_reps=True, draw_signature_heatmaps=True, draw_signatures = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download protein file from pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdbl = Bio.PDB.PDBList()\n",
    "pdbl.retrieve_pdb_file('7sx3', pdir='./ProteinFiles', file_format='mmCif')parser = MMCIFParser()\n",
    "protein_name = '7sx3'\n",
    "pointsprotein =[]\n",
    "structure = parser.get_structure(protein_name, \"ProteinFiles/\"+protein_name+\".cif\")\n",
    "model1 = structure[0]\n",
    "for Chain in model1:  \n",
    "    for Residue in Chain:\n",
    "        for Atom in Residue:\n",
    "            if Atom.get_id() == 'CA':\n",
    "                pointsprotein.append(Atom.get_coord())\n",
    "pointsprotein = np.array(pointsprotein)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPF on proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, signatures = topf_run(pointsprotein, draw_signature_heatmaps = True, m = 0.5, heatmaps_in_one = True, draw_scaled_vecs=True, simplex_chances= [1,1], draw_reps = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPF on Topological Clustering Benchmark Suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dict = {'4spheresTRUE.csv': 5, 'spaceship_v2TRUE.csv':5,'spheresAndGridTRUE.csv':6, \"Two_Spheres_2_CirclesTRUE.csv\":4, \"SphereinCircleTRUE.csv\":3, \"HalvedCircleTRUE.csv\":3, \"EllipsesInEllipsesTRUE.csv\":4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('pointsetsTRUE/dim1'):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        points_with_labels = np.loadtxt('pointsetsTRUE/dim1/'+filename, delimiter=',')\n",
    "        print(filename)\n",
    "        print(points_with_labels.shape)\n",
    "        base_points = list(points_with_labels[:,:2])\n",
    "        print(len(base_points))\n",
    "        true_labels = list(points_with_labels[:,2])\n",
    "        labels, signatures = topf_run(base_points, n_clusters = num_dict[filename], auto_num_clusters = False, draw_final_clustering = True)\n",
    "        print(\"ARI: \", sklearn.metrics.adjusted_rand_score(true_labels, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('pointsetsTRUE/dim2'):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        points_with_labels = np.loadtxt('pointsetsTRUE/dim2/'+filename, delimiter=',')\n",
    "        print(filename)\n",
    "        print(points_with_labels.shape)\n",
    "        base_points = list(points_with_labels[:,:3])\n",
    "        print(len(base_points))\n",
    "        true_labels = list(points_with_labels[:,3])\n",
    "        topf_run(base_points, n_clusters = num_dict[filename], max_hom_dim=2, auto_num_clusters = False, draw_final_clustering = True)\n",
    "        print(\"ARI: \", sklearn.metrics.adjusted_rand_score(true_labels, labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
